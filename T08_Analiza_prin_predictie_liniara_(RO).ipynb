{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T07. Analiza prin predicție liniară\n",
    "Copyright 2019 - Adriana Stan\n",
    "\n",
    "Adriana.Stan@com.utcluj.ro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/mmcauliffe/Conch-sounds/blob/master/conch/analysis/formants/lpc.py\n",
    "\n",
    "https://www.ee.columbia.edu/~dpwe/e4896/lectures/E4896-L06.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza prin predicție liniară (en. *Linear Prediction Analysis*) este o altă metodă, alături de cepstrum, de separare a sursei de filtru din modelul sursă-filtru de producere a vorbirii. Principiul fundamental al acestei analize este bazat pe gradul înalt de corelație al eșantioanelor semnalului vocal. Această corelație este dată de inerția organelor fonatoare, astfel încât sunetul emis nu poate fi modificat într-un interval de timp foarte mic. Tot această inerție stă și la baza cvasi-staționarității semnalului vocal. \n",
    "\n",
    "Datorită acestei corelații eșantioanele de semnal pot fi estimate ca o sumă ponderată a eșantioanele anterioare:\n",
    "\n",
    "$ \\hat{y[n]} = \\sum_{k=1}^{p}a_ky[n-k]$\n",
    "\n",
    "unde $p$ este ordinul de predicție. Eroarea de predicție este dată de :\n",
    "\n",
    "$ e[n] = y[n] - \\hat{y[n]}= \\sum_{k=1}^{p}y[n-k] $\n",
    "\n",
    "Dacă trecem în domeniul `z` obținem:\n",
    "\n",
    "$E(z) = Y(z) - \\sum_{k=1}^{p}a_kz^{-k}Y(z) $\n",
    "\n",
    "Împărțim ambii termeni cu $Y(z)$ și inversăm ecuația:\n",
    "\n",
    "$ \\frac{Y(z)}{E(z)} = \\frac{1}{1-\\sum_{k=1}^{p}a_kz^{-k}}$\n",
    "\n",
    "Această ecuație seamănă cu o funcție de transfer ce conține doar poli. Acest lucru este în conformitate și cu un alt model de producere a vorbirii derivat din principii de acustică teoretică. Acesta spune că tractul vocal poate fi modelat cu un set finit de tuburi de diferite lungimi și raze. Aceste tuburi introduc fiecare o pereche de poli complex conjugați în funcția de transfer a tractului vocal. Drept urmare, putem scrie $H(z)$ ca un filtru ce are doar poli:\n",
    "\n",
    "$H(z) = \\frac{1}{1- \\sum_{k=1}^{p}a_kz^{-k}}$\n",
    "\n",
    "Pornind de la aceste două observații putem conclude faptul că eroare de predicție din ecuațiile inițiale nu este altceva decât sursa semnalului vocal și anume oscilația corzilor vocale sau fluxul de aer nemodulat expirat din plămâni.\n",
    "\n",
    "Deci, pentru a determina sursa și filtrul din modelul de producere a vorbirii este suficient să determinăm coeficienții $a_k$ ai funcției de transfer anterioare. Acești coeficienți sunt denumiți **coeficienți de predicție liniară** (en. *linear prediction coefficients* (LPC)). Calculul lor implică rezolvarea unui sistem de ecuații de ordin $p$, iar pentru aceasta există o serie de metode matematice de rezolvare rapidă, dintre care cea mai des folosită este recursivitatea Levinson-Durbin https://en.wikipedia.org/wiki/Levinson_recursion . Detalierea algoritmilor de calcul ai coeficienților LPC nu face parte din scopul acestei cărți și lăsăm la latitudinea cititorului aprofundarea acestora. \n",
    "\n",
    "Să vedem acum ce informații ne oferă coeficienții LPC despre semnalul vocal. Să citim mai întâi două semnale: sonor și nesonor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "######################\n",
    "# Citim vocala\n",
    "######################\n",
    "input_wav_vowel = 'speech_files/a.wav'\n",
    "wav_struct_vowel = wave.open(input_wav_vowel, 'r')\n",
    "sampling_frequency = wav_struct_vowel.getframerate()\n",
    "wav_bytes_vowel = wav_struct_vowel.readframes(-1)\n",
    "wav_data_vowel = np.frombuffer(wav_bytes_vowel, dtype='int16')\n",
    "wav_data_vowel = wav_data_vowel/float(max(abs(wav_data_vowel)))\n",
    "wav_struct_vowel.close()\n",
    "\n",
    "######################\n",
    "# Citim consoana\n",
    "######################\n",
    "input_wav_consonant = 'speech_files/s.wav'\n",
    "wav_struct_consonant = wave.open(input_wav_consonant, 'r')\n",
    "wav_bytes_consonant = wav_struct_consonant.readframes(-1)\n",
    "wav_data_consonant = np.frombuffer(wav_bytes_consonant, dtype='int16')\n",
    "sampling_frequency_c = wav_struct_consonant.getframerate()\n",
    "wav_data_consonant = wav_data_consonant/float(max(abs(wav_data_consonant)))\n",
    "wav_struct_consonant.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru a extrage coeficienții LPC din fiecare cadru de semnal, vom folosi din nou modulul `librosa`, submodulul `core` ce conține funcția `lpc()`. Această funcție ia ca intrare un semnal și un ordin al predictorului și returnează coeficienții LPC, inclusiv termenul liber din numitorul funcției de transfer.\n",
    "\n",
    "> **(OBS)** Ordinul predictorului pentru semnalele vocale a fost stabilit empiric de către Fant ca fiind egal cu frecvența de eșantionare exprimată în kHz plus 2. Această formulă se bazează pe observația că în mediue într-un semnal vocal nu poate să existe mai mult un pol la fiecare kilohertz. Astfel că alegerea unui ordin egal cu $[F_s]+2$ funcționează și în practică."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.core as lb\n",
    "from scipy.signal import hamming\n",
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline\n",
    "\n",
    "# Fereastra de analiză cu lungime egală cu putere a lui 2 fără suprapunere\n",
    "window_length = int(20*1e-3*sampling_frequency)\n",
    "window_fft = int(2**np.ceil(np.log2(window_length)))\n",
    "p = 0\n",
    "# Fereastră Hamming\n",
    "hamming_window = hamming(window_fft)\n",
    "\n",
    "# Numărul de cadre\n",
    "number_of_frames = int(len(wav_data_vowel)/window_fft)\n",
    "\n",
    "# Stabilim ordinul LPC la Fs + 2\n",
    "lpc_order = sampling_frequency//1000 + 2\n",
    "\n",
    "# Inițializăm o matrice nulă în care vom stoca valorile\n",
    "# coeficienților LPC din fiecare cadru. Numărul\n",
    "# de coeficienți LPC returnat de funcție este egal\n",
    "# cu ordinul LPC+1 datorită termenului liber\n",
    "lpcs = np.zeros ([number_of_frames, lpc_order+1])\n",
    "for k in range(number_of_frames):\n",
    "    # Extragem doar un cadru din semnal\n",
    "    current_frame = wav_data_vowel[k*window_fft: (k+1)*window_fft]\n",
    "    hamming_frame = np.multiply(hamming_window, current_frame)\n",
    "    lpcs[k,:] = lb.lpc(hamming_frame, lpc_order)\n",
    "        \n",
    "# Plot\n",
    "pl.plot(np.transpose(lpcs))\n",
    "pl.title(\"Vowel's LPC coefficients\")\n",
    "pl.xlabel('LPC coef #');\n",
    "\n",
    "\n",
    "############\n",
    "## Consoana\n",
    "############\n",
    "\n",
    "# Numărul de cadre din consoană\n",
    "number_of_frames = int(len(wav_data_consonant)/window_fft)\n",
    "\n",
    "lpcs = np.zeros ([number_of_frames, lpc_order+1])\n",
    "for k in range(number_of_frames):\n",
    "    # Extragem doar un cadru din semnal\n",
    "    current_frame = wav_data_consonant[k*window_fft: (k+1)*window_fft]\n",
    "    hamming_frame = np.multiply(hamming_window, current_frame)\n",
    "    lpcs[k,:] = lb.lpc(hamming_frame, lpc_order)\n",
    "        \n",
    "# Plot\n",
    "pl.figure()\n",
    "pl.plot(np.transpose(lpcs))\n",
    "pl.title(\"Consonant's LPC coefficients\")\n",
    "pl.xlabel('LPC coef #');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se poate observa faptul că valorile acestor coeficienți sunt constante de-a lungul celor două segmente vocale și că valoarea primului coeficient returnat de funcția `lpc()` este întotdeauna 1. Valorile constante ale coeficienților LPC ne indică faptul că tractul vocal și filtrul determinat de acesta nu se modifică. Ceea ce este adevărat atât timp cât segmentul vocal conține o singură fonemă cu caracteristici statice, cum sunt vocalele sau anumite consoane.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr style=\"color:#FF5733; font-weight:bold\">\n",
    "    <td style=\"width:6%\">\n",
    "        <img src='images/ex1.png' width=50 align=\"left\"> </td>\n",
    "    <td>A. Afișați valorile coeficienților LPC pentru o altă consoană cu caracteristici mai dinamice, cum ar fi *p*, *c*, *d*, etc.\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "##YOUR CODE HERE\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr style=\"color:#FF5733; font-weight:bold\">\n",
    "    <td style=\"width:6%\">\n",
    "        <img src='images/ex5.png' width=50 align=\"left\"> </td>\n",
    "    <td>B. Afișați valorile coeficienților LPC pentru un segment vocal ce conține mai multe foneme. Sunt valorile coeficienților LPC constante?\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "##YOUR CODE HERE\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrul LPC\n",
    "\n",
    "\n",
    "Știind că acești coeficienți LPC sunt de fapt coeficienții unui filtru, putem să vizualizăm răspunsul său în frecvență. Vom afișa acest răspuns alături de spectrul semnalului, pentru a putea identifica eventualele similitudini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import freqz\n",
    "\n",
    "# Extragem un singur cadru al vocalei\n",
    "k = 3\n",
    "vowel_frame = wav_data_vowel[k*window_fft: (k+1)*window_fft]\n",
    "hamming_frame = np.multiply(hamming_window, current_frame)\n",
    "\n",
    "a = lb.lpc(hamming_frame, lpc_order)\n",
    "\n",
    "# Obținem răspunsul în frecvență al filtrului dat de\n",
    "# coeficienții LPC. Lungimea răspunsului o luăm egală\n",
    "# cu numărul de puncte FFT al spectrului semnalului\n",
    "w, h = freqz(1, a , window_fft//2)\n",
    "\n",
    "# Axa frecvenței\n",
    "freq_axis = np.arange(window_fft//2)*sampling_frequency/window_fft\n",
    "\n",
    "# Afișăm pe axă logaritmică spectrul LPC\n",
    "pl.plot(freq_axis, 20*np.log10(1.0/window_fft*abs(h)))\n",
    "\n",
    "# Spectrul semnalului\n",
    "pl.magnitude_spectrum(hamming_frame, Fs = sampling_frequency, scale='dB')\n",
    "pl.title(\"Signal spectrum and LPC spectrum\")\n",
    "pl.legend([\"LPC spectrum\", \"Magnitude spectrum\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Din figura anterioară putem să observăm faptul că spectrul LPC, asemeni spectrului lui $h$ dat de coeficienții cepstrali este anvelopa spectrală a spectrului semnalului. Astfel că putem să concluzionăm faptul că acești coeficienți sunt o bună aproximare a filtrului dat de tractul vocal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr style=\"color:#FF5733; font-weight:bold\">\n",
    "    <td style=\"width:6%\">\n",
    "        <img src='images/ex1.png' width=50 align=\"left\"> </td>\n",
    "    <td>B. Variați ordinul coeficienților LPC și observați modificarea spectrului LPC.\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "##YOUR CODE HERE\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr style=\"color:#FF5733; font-weight:bold\">\n",
    "    <td style=\"width:6%\">\n",
    "        <img src='images/ex3.png' width=50 align=\"left\"> </td>\n",
    "    <td>C. Afișați spectrul LPC pentru consoană.\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "##YOUR CODE HERE\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculul formanților pe baza coeficienților LPC\n",
    "\n",
    "Având mai bine evidențiată anvelopa spectrală a semnalului vocal și zonele de energie maximă locală, putem să determinăm formanții segmentelor sonore.  \n",
    "\n",
    "După cum am menționat anterior, **formanții** sunt frecvențele de rezonanță ale tractului vocal și sunt prezenți doar în cadrul segmentelor sonore. Formanții sunt un element important al analizei semnalului vocal și determină identitatea sunetului emis (vocala). Ca urmare, o primă formă de sinteză de voce, utilizată și în ziua de azi de către foneticieni, este **sinteza formantică**: https://ccrma.stanford.edu/~jos/pasp/Formant_Synthesis_Models.html\n",
    "\n",
    "Din spectrul LPC afișat anterior putem identifica punctele de energie spectrală maximă locală corespunzătoare formanților prin identificarea punctelor de inflexiune ale funcției matematice. Punctele de inflexiune sunt date de rădăcinile numărătorului funcției. \n",
    "\n",
    "Secvența de cod următoare calculează aceste rădăcini complexe și le ordonează crescător în funcție de faza lor. Valorile în Hz a formanților fiind date de formula:\n",
    "\n",
    "$F = \\frac{faza}{2\\pi}*F_s $ [Hz]\n",
    "\n",
    "În aplicații practice, se folosesc maxim primii 3-4 formanți. Vom limita și noi calculul lor la 4 valori:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_formants(input_sample, lpc_order, fs):\n",
    "    a = lb.lpc(input_sample,lpc_order)\n",
    "    \n",
    "    # Extragem rădăcinile polinomului dat de\n",
    "    # coeficienții LPC\n",
    "    roots = np.roots(a)\n",
    "    \n",
    "    # Rădăcinile sunt complex conjugate, reținem doar\n",
    "    # o valoare din pereche\n",
    "    roots = roots[np.where(np.imag(roots) > 0)]\n",
    "    \n",
    "    # Calculăm fazele rădăcinilor\n",
    "    angles = np.arctan2(np.imag(roots), np.real(roots))\n",
    "    \n",
    "    # Calculăm frecvențele\n",
    "    freqs = angles * (fs / (2 * np.pi))\n",
    "    \n",
    "    # Reordonăm în ordinea crescătoare a fazelor\n",
    "    frequency_indices = np.argsort(freqs)\n",
    "    formants = [int(x) for x in freqs[frequency_indices]]\n",
    "    # Benzile de frecvență ale formanților\n",
    "    # sunt date de distanța polilor față de\n",
    "    # cercul unitate\n",
    "    bw = -1 / 2 * (fs / (2 * np.pi)) * np.log(np.abs(roots[frequency_indices]))\n",
    "    # Frecvențele formanților trebuie să\n",
    "    # fie mai mari decât 90Hz cu o bandă\n",
    "    # de frecvențe mai mică de 400Hz\n",
    "    formants = [f for i,f in enumerate(formants) \\\n",
    "                if f>90 and bw[i]<400]\n",
    "    return formants[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extragem valorile formanților dintr-un cadru al vocalei\n",
    "formants = extract_formants(hamming_frame, lpc_order, sampling_frequency)\n",
    "print (\"Formant values: \"+' '.join([str(x)+'Hz' for x in formants]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Să afișăm aceste valori peste spectrul LPC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spectrul LPC\n",
    "pl.plot(freq_axis, 20*np.log10(abs(h)))\n",
    "\n",
    "# Plot valori formanți\n",
    "for f in formants:\n",
    "    pl.axvline(f, color = 'r')    \n",
    "pl.title(\"LPC spectrum and formant values\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valorile formanților determinate anterior se suprapun perfect cu punctele de inflexiune ale spectrului LPC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr style=\"color:#FF5733; font-weight:bold\">\n",
    "    <td style=\"width:6%\">\n",
    "        <img src='images/ex2.png' width=50 align=\"left\"> </td>\n",
    "    <td>D. Încercați să determinați formanții și pentru consoană. Ce obțineți?\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "##YOUR CODE HERE\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eroarea de predicție\n",
    "\n",
    "https://librosa.github.io/librosa/v0.1.0/index.html\n",
    "\n",
    "La începutul acestui tutorial am menționat faptul că eroarea de predicție este egală cu sursa de semnal. Să vedem cum arată această eroare de predicție. Vom filtra semnalul vocal cu filtrul invers dat de:\n",
    "\n",
    "$H(z) = \\sum_{k=1}^{p}a_kz^{-k}$\n",
    "\n",
    "pentru a obține semnalul prezis, iar mai apoi vom scădea din semnalul original semnalul prezis.\n",
    "\n",
    "Trebuie să ținem cont de modul în care funcția `lpc()` ne returnează valorile coeficienților. Și anume, acestea includ termenul liber și semnul minus dinaintea sumei de la numitor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import lfilter\n",
    "# Creăm setul de coeficienți pentru filtrul invers\n",
    "a_hat =  -1*a\n",
    "a_hat[0] = 0\n",
    "\n",
    "# Cadru din vocală\n",
    "frame = vowel_frame\n",
    "# Filtrăm cu filtrul invers\n",
    "y_hat = lfilter(a_hat, 1, frame)\n",
    "\n",
    "# Calculăm eroarea\n",
    "err = frame - y_hat\n",
    "\n",
    "# Plot\n",
    "time_axis = np.arange(0, window_fft)*1.00/sampling_frequency\n",
    "pl.plot(time_axis, frame)\n",
    "pl.plot(time_axis, y_hat)\n",
    "pl.plot(time_axis, err);\n",
    "pl.xlabel(\"Time [s]\")\n",
    "pl.title(\"LPC prediction and error signals\")\n",
    "pl.legend([\"Original frame\", \"Predicted frame\", \"Error\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observăm că semnalul prezis este foarte apropiat de semnalul original, eroarea fiind aproape zero de-a lungul acestui cadru de analiză.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr style=\"color:#FF5733; font-weight:bold\">\n",
    "    <td style=\"width:6%\">\n",
    "        <img src='images/ex3.png' width=50 align=\"left\"> </td>\n",
    "    <td>D. Calculați eroarea de predicție și pentru un cadru al consoanei? Ce observați?\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "##YOUR CODE HERE\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinteza LPC\n",
    "\n",
    "Până în momentul de față am reușit să extragem coeficienții LPC din semnal, să vizualizăm spectrul dat de acești coeficienți și să calculăm eroarea de predicție. Însă una dintre cele mai mari aplicații ale analizei LPC este cea de codare. Pe lângă extragerea coeficienților LPC este nevoie să se realizeze și sinteza semnalului vocal folosind cât mai puțini parametri transmiși sau stocați. Astfel că, dacă am reușit să utilizăm doar $Fs + 2$ coeficienți pentru a modela filtrul, trebuie să găsim și o modalitate de a reduce datele sursei. \n",
    "\n",
    "Să vedem mai întâi ce informații putem regăsi în această eroare. Afișăm eroarea absolută însă pentru un cadru neponderat Hamming, pentru a fi mai evidentă informația:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cadru din vocală\n",
    "frame = vowel_frame\n",
    "a = lb.lpc(frame, lpc_order)\n",
    "# Creăm setul de coeficienți pentru filtrul invers\n",
    "a_hat =  -1*a\n",
    "a_hat[0] = 0\n",
    "\n",
    "# Filtrăm cu filtrul invers\n",
    "y_hat = lfilter(a_hat, 1, frame)\n",
    "\n",
    "# Calculăm eroarea\n",
    "err = frame - y_hat\n",
    "\n",
    "# Eroarea pătratică\n",
    "err_square = abs(err)\n",
    "pl.plot(time_axis, err_square);\n",
    "pl.xlabel(\"Time [s]\")\n",
    "pl.title(\"Absolute error\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se poate observa că pentru secvenţe sonore, în eroarea de predicţie apar maxime distanţate cu perioada fundamentală T0 (exceptând eroarea din primele câteva eșantioane). Să încercăm să extragem $F_0$ din eroarea de predicție:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "# Reținem doar maximele distanțate cu minim\n",
    "# 1/480Hz = T0 minim și ignorând eroare\n",
    "# de început de cadru\n",
    "peaks,_ = find_peaks(err_square[20:], distance=90)\n",
    "\n",
    "# Corectăm indecșii returnați\n",
    "peaks = peaks+20\n",
    "# Calculăm distanța dintre indecșii returnați de funcție:\n",
    "difs = [x-peaks[i-1] for i,x in enumerate(peaks)][1:]\n",
    "\n",
    "# Determinăm media diferențelor\n",
    "average_dist = np.mean(difs)\n",
    "# Și o convertim în Hz\n",
    "F0 = sampling_frequency/average_dist \n",
    "# Afișăm\n",
    "print (\"F0 estimated from LPC error: %d Hz\" %(int(F0)))\n",
    "\n",
    "pl.plot(time_axis, err_square);\n",
    "for z in peaks:\n",
    "    pl.axvline(z*1.0/sampling_frequency, color = 'r')\n",
    "pl.xlabel(\"Time [s]\")\n",
    "pl.title(\"Absolute error with peak detection\");    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dacă eroarea de predicție conține aceste maxime distanțate cu $T_0$, iar această eroare reprezintă sursa ideală de semnal pentru filtrul LPC, am putea să încercăm să modelăm această sursă cu impulsuri Dirac poziționate la indecșii maximelor și de amplitudine egală cu acestea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector pentru sursa Dirac\n",
    "dirac_source = np.zeros(window_fft)\n",
    "dirac_source[peaks] = err[peaks]\n",
    "pl.plot(time_axis, dirac_source)\n",
    "pl.ylim([-0.10,0.10])\n",
    "pl.xlabel(\"Time [s]\")\n",
    "pl.title(\"Dirac source estimation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrăm sursa Dirac cu filtrul LPC:\n",
    "dirac_synth = lfilter([1.],a, dirac_source)\n",
    "# Normalizăm pentru că nu am calculat\n",
    "# câștigul filtrului LPC\n",
    "dirac_synth = dirac_synth/(max(abs(dirac_synth)))\n",
    "\n",
    "# Plot\n",
    "time_axis = np.arange(0, window_fft)*1.00/sampling_frequency\n",
    "pl.plot(time_axis, dirac_synth)\n",
    "pl.plot(time_axis, vowel_frame)\n",
    "pl.xlabel(\"Time [s]\")\n",
    "pl.legend([\"Dirac synth\", \"Original frame\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetăm cadrul pentru a putea auzi rezultatul\n",
    "dirac_synth_long = np.tile(dirac_synth, 3)\n",
    "\n",
    "# Ascultăm sinteza\n",
    "import IPython\n",
    "IPython.display.Audio(dirac_synth_long, rate=sampling_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ascultăm și semnalul original\n",
    "IPython.display.Audio(wav_data_vowel, rate=sampling_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr style=\"color:#FF5733; font-weight:bold\">\n",
    "    <td style=\"width:6%\">\n",
    "        <img src='images/ex2.png' width=50 align=\"left\"> </td>\n",
    "    <td>D. Reluați pașii de sinteză folosind altă vocală. Poate fi determinată identitatea vocalei din sinteza cu impulsuri Dirac?\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "##YOUR CODE HERE\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pentru consoane se folosește zgomot alb gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cadrul consoanei\n",
    "consonant_frame= wav_data_consonant[k*window_fft: (k+1)*window_fft]\n",
    "noise = np.random.normal(scale=0.05*np.max(consonant_frame), size=window_fft)\n",
    "\n",
    "# Filtrare inversă consoană\n",
    "a = lb.lpc(consonant_frame, lpc_order)\n",
    "noise_synth = lfilter([1],a, noise)\n",
    "\n",
    "noise_synth = noise_synth/max(abs(noise_synth))\n",
    "noise_synth_long = np.tile(noise_synth, 10)\n",
    "pl.plot(time_axis,consonant_frame)\n",
    "pl.plot(time_axis, noise_synth)\n",
    "pl.xlabel(\"Time [s]\")\n",
    "pl.title(\"Consonant LPC synth from gaussian noise\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(noise_synth, rate=sampling_frequency_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(wav_data_consonant, rate=sampling_frequency_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr style=\"color:#FF5733; font-weight:bold\">\n",
    "    <td style=\"width:6%\">\n",
    "        <img src='images/ex2.png' width=50 align=\"left\"> </td>\n",
    "    <td>D. Încercați să realizați sinteza LPC pe un întreg semnal vocal făcând distincția automat între consoane și vocale pe baza erorii de predicție.\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "##YOUR CODE HERE\n",
    "###################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "În mod evident, simplificând atât de mult sursa de semnal va rezulta într-o degradare majoră a calității semnalului sintetizat. Pentru a evita acest lucru se folosesc combinații de impulsuri și zgomot cu ponderi variabile atât pentru consoane, cât și pentru vocale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluzii\n",
    "\n",
    "În cadrul acestui tutorial am introdus analiza prin predicție liniară. Această analiză permite separarea surseri de filtru din modelul liniar-separabil de producere a vorbirii. Am văzut totodată și modul în care putem calcul formanții segmentelor sonore pornind de la spectrul dat de coeficienții LPC, precum și modul în care putem realiza sinteza LPC minimizând informația din sursa de semnal. De altfel, una dintre cele mai importante aplicații ale analizei prin predicție liniară este cea de codare. Metoda de codare din GSM  - o variantă a Code Excited Linear Prediction - utilizează acest tip de analiză. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
